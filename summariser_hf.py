import os
import docx
import json
import re
from PyPDF2 import PdfReader
from fpdf import FPDF
from datetime import datetime
from transformers import pipeline
from keybert import KeyBERT

def extract_text_from_txt(file_path):
    """Extract text from TXT file."""
    with open(file_path, 'r', encoding='utf-8') as file:
        return file.read()

def extract_text_from_pdf(file_path):
    """Extract text from PDF file."""
    pdf_reader = PdfReader(file_path)
    text = ""
    for page in pdf_reader.pages:
        page_text = page.extract_text()
        if page_text:
            text += page_text + "\n"
    return text

def extract_text_from_docx(file_path):
    """Extract text from DOCX file."""
    doc = docx.Document(file_path)
    return "\n".join(para.text for para in doc.paragraphs)

def split_into_sections(text):
    """Split text into logical sections based on common legal headings."""
    sections = {}
    current_section = "Introduction"
    sections[current_section] = []

    legal_headers = [
        "DEFINITIONS", "PAYMENT", "LICENSE", "CONFIDENTIALITY", 
        "LIABILITY", "INDEMNITIES", "TERMINATION", "WARRANTIES", 
        "GOVERNING LAW", "PRIVACY", "COOKIES", "DATA", "SERVICES",
        "ACCOUNT", "CONTENT", "INTELLECTUAL PROPERTY", "DISPUTE"
    ]

    for line in text.splitlines():
        line_upper = line.strip().upper()
        
        if any(header in line_upper for header in legal_headers):
            current_section = line.strip()
            sections[current_section] = []
        else:
            sections[current_section].append(line)
    
    for section, lines in sections.items():
        sections[section] = " ".join(lines).strip()
    
    return sections

def summarize_text_hf(text):
    """Summarize text using nsi319/legal-pegasus model."""
    summarizer = pipeline("summarization", model="nsi319/legal-pegasus")
    summary = summarizer(text, max_length=150, min_length=30, do_sample=False)
    return summary[0]['summary_text']

def extract_keywords_bert(text):
    """Extract keywords using KeyBERT."""
    kw_model = KeyBERT()
    keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 2), stop_words='english', top_n=5)
    return [keyword for keyword, _ in keywords]

def summarize_sections(sections, min_length=150, max_length=300):
    """Create summaries for each section using Hugging Face and KeyBERT."""
    summaries = {}
    
    for section_name, content in sections.items():
        if not content.strip():
            continue
            
        summary_text = summarize_text_hf(content)
        keywords = extract_keywords_bert(content)
        
        formatted_summary = f"{summary_text}\n\nKey Terms: {', '.join(keywords)}"
        summaries[section_name] = formatted_summary.strip()
    
    return summaries

def compile_final_summary(summaries):
    """Compile summaries with enhanced formatting."""
    header = "=" * 60 + "\n"
    header += "TERMS & CONDITIONS SUMMARY (HF)\n"
    header += "=" * 60 + "\n\n"
    
    if len(summaries) > 1:
        header += "üîç EXECUTIVE OVERVIEW\n"
        header += "-" * 25 + "\n"
        header += "This document has been analyzed and summarized into key sections below.\n"
        header += "Each section contains the most important points in plain language.\n\n"
    
    formatted_sections = []
    
    for section_name, summary in summaries.items():
        section_header = f"{section_name.upper()}\n"
        section_header += "-" * (len(section_name) + 4) + "\n"
        
        formatted_section = section_header + summary + "\n"
        formatted_sections.append(formatted_section)
    
    footer = "\n" + "=" * 60 + "\n"
    footer += "IMPORTANT DISCLAIMER\n"
    footer += "=" * 60 + "\n"
    footer += "This is a summary generated by a Hugging Face model for informational purposes only.\n"
    footer += "Please refer to the original document for complete legal terms.\n"
    footer += "Consult with legal professionals for important decisions.\n"
    
    final_summary = header + "\n\n".join(formatted_sections) + footer
    return final_summary

def clean_text_for_pdf(text):
    """Clean text for PDF compatibility by replacing Unicode characters with ASCII equivalents."""
    unicode_replacements = {
        '‚Ä¢': '* ',      # Bullet point
        '‚ó¶': '- ',      # White bullet
        '‚ñ™': '* ',      # Black small square
        '‚ñ´': '- ',      # White small square
        '‚Äì': '-',       # En dash
        '‚Äî': '--',      # Em dash
        ''': "'",       # Left single quotation mark
        ''': "'",       # Right single quotation mark
        '"': '"',       # Left double quotation mark
        '"': '"',       # Right double quotation mark
        '‚Ä¶': '...',     # Horizontal ellipsis
        '¬©': '(c)',     # Copyright symbol
        '¬Æ': '(R)',     # Registered trademark
        '‚Ñ¢': '(TM)',    # Trademark symbol
        '¬∞': ' deg',    # Degree symbol
        '¬ß': 'Section', # Section symbol
        '¬∂': 'Para',    # Paragraph symbol
    }
    
    # Replace Unicode characters with ASCII equivalents
    for unicode_char, ascii_replacement in unicode_replacements.items():
        text = text.replace(unicode_char, ascii_replacement)
    
    # Handle any remaining non-ASCII characters by encoding to latin-1 with replacement
    try:
        text.encode('latin-1')
        return text
    except UnicodeEncodeError:
        return text.encode('latin-1', 'replace').decode('latin-1')

def save_summary_as_pdf(summary, output_path="static/summary_output.pdf"):
    """Create a professionally formatted PDF."""
    os.makedirs("static", exist_ok=True)
    
    summary = clean_text_for_pdf(summary)
    pdf = FPDF()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.add_page()
    
    # Add header
    pdf.set_font("Arial", style="B", size=16)
    pdf.set_text_color(0, 51, 102)
    pdf.cell(0, 10, "Legal Document Analysis (HuggingFace)", ln=True, align="C")
    pdf.ln(5)
    
    # Add generation date
    pdf.set_font("Arial", size=10)
    pdf.set_text_color(128, 128, 128)
    pdf.cell(0, 5, f"Generated on: {datetime.now().strftime('%B %d, %Y at %I:%M %p')}", ln=True, align="C")
    pdf.ln(10)
    
    # Process content
    lines = summary.split('\n')
    
    for line in lines:
        line = line.strip()
        if not line:
            pdf.ln(2)
            continue
        
        pdf.set_text_color(0, 0, 0)
        
        if line.startswith('=') and line.endswith('='):
            header_text = line.replace('=', '').strip()
            if header_text:
                pdf.set_font("Arial", style="B", size=14)
                pdf.set_text_color(0, 51, 102)
                pdf.cell(0, 8, header_text, ln=True, align="C")
                pdf.ln(3)
        
        elif line.startswith('* '):
            bullet_text = line[2:].strip()
            pdf.set_font("Arial", size=10)
            pdf.set_text_color(0, 0, 0)
            pdf.cell(5, 6, chr(149), ln=False)
            pdf.multi_cell(0, 6, bullet_text)
            pdf.ln(1)
        
        elif line.startswith('-'):
            pdf.set_font("Arial", size=10)
            pdf.set_text_color(128, 128, 128)
            pdf.cell(0, 4, line, ln=True)
            pdf.ln(1)
        
        else:
            pdf.set_font("Arial", size=10)
            pdf.set_text_color(0, 0, 0)
            pdf.multi_cell(0, 6, line)
            pdf.ln(1)
    
    # Add footer
    pdf.ln(10)
    pdf.set_font("Arial", style="I", size=9)
    pdf.set_text_color(128, 128, 128)
    pdf.multi_cell(0, 4, "This analysis was generated using Legal Pegasus and KeyBERT. Please consult legal professionals for important decisions.")
    
    pdf.output(output_path)

def store_feedback(feedback_text, feedback_file="feedback.json"):
    """Store user feedback."""
    feedback_data = {
        "feedback": feedback_text,
        "timestamp": datetime.now().isoformat()
    }
    
    try:
        with open(feedback_file, "a") as file:
            json.dump(feedback_data, file)
            file.write("\n")
    except Exception as e:
        pass  # Silently handle feedback storage errors

def answer_question(text, question):
    return "Q&A feature requires GenAI mode. Please wait till it's available."
